{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab887269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20134344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffed6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv_bi = CountVectorizer(ngram_range=(2 , 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b862b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=['the quick brown fox.','Jumps over the lazy dog!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcd3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fit=cv.fit_transform(text) ## to get count of each word\n",
    "c=cv_bi.fit_transform(text)  ## to get count of all bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a6331cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count=cv_fit.toarray().sum(axis=0) # count of words\n",
    "word_list=cv.get_feature_names_out() #list of words\n",
    "count_word = dict(zip(word_list , word_count))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db424aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown': 1,\n",
       " 'dog': 1,\n",
       " 'fox': 1,\n",
       " 'jumps': 1,\n",
       " 'lazy': 1,\n",
       " 'over': 1,\n",
       " 'quick': 1,\n",
       " 'the': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda67ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_list=cv_bi.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a83bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brown fox', 'jumps over', 'lazy dog', 'over the', 'quick brown',\n",
       "       'the lazy', 'the quick'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26af4543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27f4d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_count=c.toarray().sum(axis=0) # count of words\n",
    "count_bi = dict(zip(bigram_list , bi_count))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d0f338d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown fox': 1,\n",
       " 'jumps over': 1,\n",
       " 'lazy dog': 1,\n",
       " 'over the': 1,\n",
       " 'quick brown': 1,\n",
       " 'the lazy': 1,\n",
       " 'the quick': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80dd1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words=word_count.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e5fd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brown', 'dog', 'fox', 'jumps', 'lazy', 'over', 'quick', 'the'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b279e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sequence= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4813526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_word(text):\n",
    "    fw_list=[t.split()[0]for t in text]\n",
    "    return fw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea34b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_list=get_first_word(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641a07a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'Jumps']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e28aad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV=CountVectorizer() ## to get count of first word of Sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9462921d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cc871702",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m CV\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1484\u001b[0m, in \u001b[0;36mCountVectorizer.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_names_out\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \n\u001b[0;32m   1474\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03m        Transformed feature names.\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1484\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_vocabulary()\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m   1486\u001b[0m         [t \u001b[38;5;28;01mfor\u001b[39;00m t, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39mitemgetter(\u001b[38;5;241m1\u001b[39m))],\n\u001b[0;32m   1487\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m,\n\u001b[0;32m   1488\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:510\u001b[0m, in \u001b[0;36m_VectorizerMixin._check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_vocabulary()\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_:\n\u001b[1;32m--> 510\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary not fitted or provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "CV.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90fc9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi(fw_list):\n",
    "    pi={word : fw_list.count(word)/(total_words+len(fw_list)) for word in fw_list} ##add one smoothening\n",
    "    return pi\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "004dcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi=pi(fw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e5b105d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.09090909090909091, 'Jumps': 0.09090909090909091}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95425772",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.zeros([total_words , total_words]) #transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d893238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brown', 'dog', 'fox', 'jumps', 'lazy', 'over', 'quick', 'the'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f68f447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape\n",
    "B={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "542f85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown fox 1 1\n",
      "jumps over 1 1\n",
      "lazy dog 1 1\n",
      "over the 1 1\n",
      "quick brown 1 1\n",
      "the lazy 1 2\n",
      "the quick 1 2\n"
     ]
    }
   ],
   "source": [
    "for i , word in enumerate(word_list):\n",
    "    for j , next_word in enumerate(word_list):\n",
    "        count=0\n",
    "        for bigram in count_bi:\n",
    "            if bigram.split()[0] == word and bigram.split()[1]==next_word:\n",
    "                count=count_bi[bigram]\n",
    "                print(bigram , count , count_word[bigram.split()[0]])\n",
    "            A[i , j]=(count+1)/(count_word[bigram.split()[0]]+len(word_list)) ## Add one smoothening we can make it different by epsilon>1 or <1\n",
    "            B[word+\" \"+next_word] = (count+1)/(count_word[bigram.split()[0]] +len(word_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "08be65d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brown', 'dog', 'fox', 'jumps', 'lazy', 'over', 'quick', 'the'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ad11a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['brown', 'fox'], ['jumps', 'over'], ['lazy', 'dog'], ['over', 'the'], ['quick', 'brown'], ['the', 'lazy'], ['the', 'quick']]\n"
     ]
    }
   ],
   "source": [
    "print([y.split() for y in bigram_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f162fdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0. ],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0. ],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0. ],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0. ],\n",
       "       [0.1, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0. ],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0. ],\n",
       "       [0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0. ],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.2, 0.1, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7821f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ec8b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bi=cv_fit.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee67414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceb12bdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (9, 9), indices imply (9, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bigrams_pb\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mA , columns\u001b[38;5;241m=\u001b[39mbigram_list)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:758\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    747\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    748\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    749\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    755\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    756\u001b[0m         )\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 758\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    759\u001b[0m             data,\n\u001b[0;32m    760\u001b[0m             index,\n\u001b[0;32m    761\u001b[0m             columns,\n\u001b[0;32m    762\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    763\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    764\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    765\u001b[0m         )\n\u001b[0;32m    767\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:337\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    333\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    334\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    335\u001b[0m )\n\u001b[1;32m--> 337\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:408\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    406\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    407\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 408\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (9, 9), indices imply (9, 7)"
     ]
    }
   ],
   "source": [
    "bigrams_pb=pd.DataFrame(data=A , columns=bigram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_sequence(sequence):\n",
    "    \n",
    "    ans=1\n",
    "    for bi in sequence.split():\n",
    "        ans*=df[bi]\n",
    "    ans*=pi[sequence.split()[0]]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "82523ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d18348fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probability_sequence(sequence):\n",
    "    log_probability=0\n",
    "    bigram = [[sequence.split()[i] + \" \" +sequence.split()[i+1]] for i in range(0 , len(sequence.split())-1)]\n",
    "    \n",
    "    for bi in bigram:\n",
    "        print(bi[0])\n",
    "        log_probability+=math.log(B[bi[0]]) ##we need probability \n",
    "    log_probability+=math.log(pi[sequence.split()[0]])\n",
    "    return log_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314cb9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0b1bda48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-4.007333185232471"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probability_sequence(\"the quick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3e386152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.007333185232471"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(B['the quick'])+math.log(pi[\"the quick\".split()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1df4c7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6094379124341003"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(B['the quick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "df48edb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09090909090909091"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35aaba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
